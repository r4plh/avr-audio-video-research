{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Latent Representation (1024D) Visualization\n",
    "\n",
    "This notebook uses the **latent representation `z`** from DAC for visualization.\n",
    "\n",
    "## Why Latent `z`?\n",
    "- **1024D**: Richest representation (128Ã— larger than 8D, 10Ã— larger than 96D)\n",
    "- **Full audio features**: Complete internal representation after encoder + quantization\n",
    "- **Best for clustering**: Expected to significantly outperform codebook embeddings\n",
    "\n",
    "## Strategy:\n",
    "```\n",
    "audio â†’ encoder â†’ quantizer â†’ z [1, 1024, time]\n",
    "                                â†“\n",
    "                        mean pool time\n",
    "                                â†“\n",
    "                        embedding [1024D]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our utilities\n",
    "from dac_utils import DACProcessor, SpeechCommandsLoader\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize DAC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dac_processor = DACProcessor(model_type=\"16khz\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Custom Extraction Function Using Latent `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latent_embedding(dac_processor, audio_path):\n",
    "    \"\"\"\n",
    "    Extract DAC latent representation z\n",
    "    \n",
    "    Returns:\n",
    "        1024D vector (latent representation averaged over time)\n",
    "    \"\"\"\n",
    "    # Encode audio\n",
    "    encoded = dac_processor.encode_audio(audio_path)\n",
    "    z = encoded['z']  # [1, 1024, time]\n",
    "    \n",
    "    # Mean pool across time dimension only\n",
    "    time_pooled = z.mean(dim=2)  # [1, 1024]\n",
    "    \n",
    "    # Convert to numpy\n",
    "    vector = time_pooled.squeeze(0).detach().cpu().numpy()  # [1024]\n",
    "    \n",
    "    return vector\n",
    "\n",
    "print(\"Latent extraction function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test on Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the extraction\n",
    "loader = SpeechCommandsLoader()\n",
    "file_paths, labels = loader.load_word_samples(['zero'], samples_per_word=1)\n",
    "\n",
    "if len(file_paths) > 0:\n",
    "    test_file = file_paths[0]\n",
    "    print(f\"Testing with: {test_file}\\n\")\n",
    "    \n",
    "    embedding = extract_latent_embedding(dac_processor, test_file)\n",
    "    \n",
    "    print(f\"Embedding shape: {embedding.shape}  # Should be (1024,)\")\n",
    "    print(f\"\\nFirst 10 values: {embedding[:10]}\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Min: {embedding.min():.4f}\")\n",
    "    print(f\"  Max: {embedding.max():.4f}\")\n",
    "    print(f\"  Mean: {embedding.mean():.4f}\")\n",
    "    print(f\"  Std: {embedding.std():.4f}\")\n",
    "    print(f\"\\nâœ… This is the RICHEST representation - 1024D!\")\n",
    "else:\n",
    "    print(\"No audio files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Dataset - 5 Words, 10 Samples Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 words for visualization\n",
    "words = ['zero', 'one', 'two', 'yes', 'no']\n",
    "samples_per_word = 10\n",
    "\n",
    "# Load audio paths\n",
    "file_paths, file_labels = loader.load_word_samples(words, samples_per_word=samples_per_word)\n",
    "\n",
    "print(f\"Total samples: {len(file_paths)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "for word in words:\n",
    "    count = file_labels.count(word)\n",
    "    print(f\"  {word}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Latent Embeddings for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latent embeddings for all samples\n",
    "embeddings_list = []\n",
    "valid_labels = []\n",
    "\n",
    "for file_path, label in tqdm(zip(file_paths, file_labels), total=len(file_paths), desc=\"Extracting latent embeddings\"):\n",
    "    try:\n",
    "        embedding = extract_latent_embedding(dac_processor, file_path)\n",
    "        embeddings_list.append(embedding)\n",
    "        valid_labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "embeddings = np.array(embeddings_list)\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"Final embeddings shape: {embeddings.shape}  # Should be (50, 1024)\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}D (LATENT REPRESENTATION)\")\n",
    "print(f\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: PCA Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - 2D\n",
    "pca_2d = PCA(n_components=2, random_state=42)\n",
    "pca_2d_result = pca_2d.fit_transform(embeddings)\n",
    "variance_2d = pca_2d.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"PCA 2D variance explained: {variance_2d:.2%}\")\n",
    "\n",
    "# Create color map\n",
    "color_map = {word: px.colors.qualitative.Plotly[i] for i, word in enumerate(words)}\n",
    "\n",
    "# 2D Plot\n",
    "fig_2d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_2d.add_trace(go.Scatter(\n",
    "        x=pca_2d_result[mask, 0],\n",
    "        y=pca_2d_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=12, color=color_map[word], opacity=0.7, line=dict(width=0.5, color='white'))\n",
    "    ))\n",
    "\n",
    "fig_2d.update_layout(\n",
    "    title=f'PCA 2D: DAC Latent Embeddings (1024D) - Variance: {variance_2d:.1%}',\n",
    "    xaxis_title='PC 1',\n",
    "    yaxis_title='PC 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    xaxis=dict(scaleanchor='y', scaleratio=1),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_2d.write_html('dac_latent_pca_2d.html')\n",
    "fig_2d.show()\n",
    "\n",
    "print(\"Saved: dac_latent_pca_2d.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - 3D\n",
    "pca_3d = PCA(n_components=3, random_state=42)\n",
    "pca_3d_result = pca_3d.fit_transform(embeddings)\n",
    "variance_3d = pca_3d.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"PCA 3D variance explained: {variance_3d:.2%}\")\n",
    "\n",
    "# 3D Plot\n",
    "fig_3d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_3d.add_trace(go.Scatter3d(\n",
    "        x=pca_3d_result[mask, 0],\n",
    "        y=pca_3d_result[mask, 1],\n",
    "        z=pca_3d_result[mask, 2],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=6, color=color_map[word], opacity=0.7, line=dict(width=0))\n",
    "    ))\n",
    "\n",
    "fig_3d.update_layout(\n",
    "    title=f'PCA 3D: DAC Latent Embeddings (1024D) - Variance: {variance_3d:.1%}',\n",
    "    scene=dict(\n",
    "        xaxis_title='PC 1',\n",
    "        yaxis_title='PC 2',\n",
    "        zaxis_title='PC 3',\n",
    "        aspectmode='cube',\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_3d.write_html('dac_latent_pca_3d.html')\n",
    "fig_3d.show()\n",
    "\n",
    "print(\"Saved: dac_latent_pca_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: t-SNE Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE - 2D\n",
    "perplexity = min(30, len(embeddings) - 1)\n",
    "tsne_2d = TSNE(n_components=2, random_state=42, metric='cosine', perplexity=perplexity)\n",
    "tsne_2d_result = tsne_2d.fit_transform(embeddings)\n",
    "\n",
    "print(f\"t-SNE 2D completed with perplexity={perplexity}\")\n",
    "\n",
    "# 2D Plot\n",
    "fig_tsne_2d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_tsne_2d.add_trace(go.Scatter(\n",
    "        x=tsne_2d_result[mask, 0],\n",
    "        y=tsne_2d_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=12, color=color_map[word], opacity=0.7, line=dict(width=0.5, color='white'))\n",
    "    ))\n",
    "\n",
    "fig_tsne_2d.update_layout(\n",
    "    title=f't-SNE 2D: DAC Latent Embeddings (1024D) - Perplexity={perplexity}',\n",
    "    xaxis_title='t-SNE 1',\n",
    "    yaxis_title='t-SNE 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    xaxis=dict(scaleanchor='y', scaleratio=1),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_tsne_2d.write_html('dac_latent_tsne_2d.html')\n",
    "fig_tsne_2d.show()\n",
    "\n",
    "print(\"Saved: dac_latent_tsne_2d.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE - 3D\n",
    "tsne_3d = TSNE(n_components=3, random_state=42, metric='cosine', perplexity=perplexity)\n",
    "tsne_3d_result = tsne_3d.fit_transform(embeddings)\n",
    "\n",
    "print(f\"t-SNE 3D completed with perplexity={perplexity}\")\n",
    "\n",
    "# 3D Plot\n",
    "fig_tsne_3d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_tsne_3d.add_trace(go.Scatter3d(\n",
    "        x=tsne_3d_result[mask, 0],\n",
    "        y=tsne_3d_result[mask, 1],\n",
    "        z=tsne_3d_result[mask, 2],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=6, color=color_map[word], opacity=0.7, line=dict(width=0))\n",
    "    ))\n",
    "\n",
    "fig_tsne_3d.update_layout(\n",
    "    title=f't-SNE 3D: DAC Latent Embeddings (1024D) - Perplexity={perplexity}',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE 1',\n",
    "        yaxis_title='t-SNE 2',\n",
    "        zaxis_title='t-SNE 3',\n",
    "        aspectmode='cube',\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_tsne_3d.write_html('dac_latent_tsne_3d.html')\n",
    "fig_tsne_3d.show()\n",
    "\n",
    "print(\"Saved: dac_latent_tsne_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Combined Dashboard View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[\n",
    "        [{'type': 'scatter'}, {'type': 'scatter3d'}],\n",
    "        [{'type': 'scatter'}, {'type': 'scatter3d'}]\n",
    "    ],\n",
    "    subplot_titles=(\n",
    "        f'PCA 2D (Var: {variance_2d:.1%})',\n",
    "        f'PCA 3D (Var: {variance_3d:.1%})',\n",
    "        f't-SNE 2D (Perp: {perplexity})',\n",
    "        f't-SNE 3D (Perp: {perplexity})'\n",
    "    ),\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# PCA 2D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pca_2d_result[mask, 0],\n",
    "            y=pca_2d_result[mask, 1],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=8, color=color_map[word], opacity=0.7),\n",
    "            showlegend=True,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# PCA 3D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=pca_3d_result[mask, 0],\n",
    "            y=pca_3d_result[mask, 1],\n",
    "            z=pca_3d_result[mask, 2],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=5, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# t-SNE 2D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=tsne_2d_result[mask, 0],\n",
    "            y=tsne_2d_result[mask, 1],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=8, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# t-SNE 3D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=tsne_3d_result[mask, 0],\n",
    "            y=tsne_3d_result[mask, 1],\n",
    "            z=tsne_3d_result[mask, 2],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=5, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='DAC Latent Embeddings (1024D) - Complete Visualization',\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    width=1400,\n",
    "    height=1000,\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='PC 1', row=1, col=1, scaleanchor='y', scaleratio=1)\n",
    "fig.update_yaxes(title_text='PC 2', row=1, col=1)\n",
    "fig.update_xaxes(title_text='t-SNE 1', row=2, col=1, scaleanchor='y3', scaleratio=1)\n",
    "fig.update_yaxes(title_text='t-SNE 2', row=2, col=1)\n",
    "\n",
    "fig.update_scenes(aspectmode='cube', row=1, col=2)\n",
    "fig.update_scenes(aspectmode='cube', row=2, col=2)\n",
    "\n",
    "fig.write_html('dac_latent_complete.html')\n",
    "fig.show()\n",
    "\n",
    "print(\"Saved: dac_latent_complete.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Clustering Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numeric\n",
    "label_to_idx = {word: i for i, word in enumerate(words)}\n",
    "numeric_labels = np.array([label_to_idx[label] for label in valid_labels])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CLUSTERING QUALITY METRICS - LATENT REPRESENTATION (1024D)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Original embeddings\n",
    "if len(np.unique(numeric_labels)) > 1 and len(embeddings) > len(np.unique(numeric_labels)):\n",
    "    sil_orig = silhouette_score(embeddings, numeric_labels)\n",
    "    db_orig = davies_bouldin_score(embeddings, numeric_labels)\n",
    "    print(f\"\\nðŸš€ Original Embeddings (1024D - LATENT):\")\n",
    "    print(f\"  Silhouette Score: {sil_orig:.4f}  (higher is better, range: -1 to 1)\")\n",
    "    print(f\"  Davies-Bouldin Score: {db_orig:.4f}  (lower is better, >0)\")\n",
    "\n",
    "# PCA 2D\n",
    "sil_pca2d = silhouette_score(pca_2d_result, numeric_labels)\n",
    "db_pca2d = davies_bouldin_score(pca_2d_result, numeric_labels)\n",
    "print(f\"\\nPCA 2D:\")\n",
    "print(f\"  Silhouette Score: {sil_pca2d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_pca2d:.4f}\")\n",
    "\n",
    "# PCA 3D\n",
    "sil_pca3d = silhouette_score(pca_3d_result, numeric_labels)\n",
    "db_pca3d = davies_bouldin_score(pca_3d_result, numeric_labels)\n",
    "print(f\"\\nPCA 3D:\")\n",
    "print(f\"  Silhouette Score: {sil_pca3d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_pca3d:.4f}\")\n",
    "\n",
    "# t-SNE 2D\n",
    "sil_tsne2d = silhouette_score(tsne_2d_result, numeric_labels)\n",
    "db_tsne2d = davies_bouldin_score(tsne_2d_result, numeric_labels)\n",
    "print(f\"\\nt-SNE 2D:\")\n",
    "print(f\"  Silhouette Score: {sil_tsne2d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_tsne2d:.4f}\")\n",
    "\n",
    "# t-SNE 3D\n",
    "sil_tsne3d = silhouette_score(tsne_3d_result, numeric_labels)\n",
    "db_tsne3d = davies_bouldin_score(tsne_3d_result, numeric_labels)\n",
    "print(f\"\\nt-SNE 3D:\")\n",
    "print(f\"  Silhouette Score: {sil_tsne3d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_tsne3d:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nðŸ“Š COMPARISON WITH OTHER APPROACHES:\")\n",
    "print(\"\\n1ï¸âƒ£  Codebook Averaging (8D):\")\n",
    "print(\"    Silhouette: -0.0731  |  Davies-Bouldin: 4.99\")\n",
    "print(\"\\n2ï¸âƒ£  Codebook Concatenation (96D):\")\n",
    "print(\"    Silhouette: ~0.1     |  Davies-Bouldin: ~3.5  [Expected]\")\n",
    "print(f\"\\n3ï¸âƒ£  Latent Representation (1024D) - THIS NOTEBOOK:\")\n",
    "print(f\"    Silhouette: {sil_orig:.4f}  |  Davies-Bouldin: {db_orig:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Expected: Latent (1024D) should significantly outperform both!\")\n",
    "print(\"   Target: Silhouette > 0.3, Davies-Bouldin < 2.0\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated DAC **latent representation visualization (1024D)**:\n",
    "\n",
    "### **Why Latent `z` is Best**:\n",
    "- âœ… **1024D**: Richest representation (128Ã— larger than 8D codebook embeddings)\n",
    "- âœ… **Complete features**: Full internal audio representation after encoder + quantization\n",
    "- âœ… **Similar to Wav2Vec2/Whisper**: Comparable dimensionality (768-1024D)\n",
    "- âœ… **Best clustering**: Should show much better word separation\n",
    "\n",
    "### **Comparison Table**:\n",
    "\n",
    "| Approach | Dimension | Silhouette | Davies-Bouldin | Quality |\n",
    "|----------|-----------|------------|----------------|----------|\n",
    "| Codebook (avg) | 8D | -0.07 | 4.99 | âŒ Poor |\n",
    "| Codebook (concat) | 96D | ~0.1 | ~3.5 | âš ï¸ Medium |\n",
    "| **Latent `z`** | **1024D** | **See above** | **See above** | âœ… **Best** |\n",
    "\n",
    "### **Key Findings**:\n",
    "- Look at the metrics above to compare with 8D and 96D versions\n",
    "- Visual inspection: Are clusters more separated in the plots?\n",
    "- This is the recommended approach for DAC embedding visualization!\n",
    "\n",
    "### **Next Steps**:\n",
    "1. âœ… Compare all three DAC approaches: 8D vs 96D vs 1024D\n",
    "2. âœ… Compare DAC latent (1024D) with Wav2Vec2 (768D) and Whisper (384-1024D)\n",
    "3. Consider integrating best approach into main dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
