{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Discrete Indices Visualization\n",
    "\n",
    "This notebook explores the discrete token indices produced by DAC (Descript Audio Codec).\n",
    "\n",
    "## What we're exploring:\n",
    "- DAC encodes audio into 9 parallel codebooks\n",
    "- Each codebook has 1024 possible values (indices 0-1023)\n",
    "- We'll visualize how different words map to different token patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Import our utilities\n",
    "from dac_utils import DACProcessor, SpeechCommandsLoader, extract_dac_embeddings_batch\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Explore DAC Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DAC processor (using 16khz for Speech Commands)\n",
    "# Speech Commands dataset is 16kHz, so we'll use the 16kHz DAC model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dac_processor = DACProcessor(model_type=\"16khz\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore model structure\n",
    "model = dac_processor.model\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DAC MODEL STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample Rate: {model.sample_rate}Hz\")\n",
    "print(f\"Hop Length: {model.hop_length} samples\")\n",
    "print(f\"Latent Dim: {model.latent_dim}\")\n",
    "print(f\"\\nQuantizer:\")\n",
    "print(f\"  - Number of codebooks: {model.n_codebooks}\")\n",
    "print(f\"  - Codebook size: {model.codebook_size} entries\")\n",
    "print(f\"  - Codebook dim: {model.codebook_dim}\")\n",
    "print(f\"\\nQuantizer Details:\")\n",
    "for i, quantizer in enumerate(model.quantizer.quantizers):\n",
    "    print(f\"  Codebook {i}:\")\n",
    "    print(f\"    - Embedding shape: {quantizer.codebook.weight.shape}\")\n",
    "    print(f\"    - in_proj: {quantizer.in_proj}\")\n",
    "    print(f\"    - out_proj: {quantizer.out_proj}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Sample Audio and Inspect Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single audio sample to understand the output format\n",
    "loader = SpeechCommandsLoader()\n",
    "file_paths, labels = loader.load_word_samples(['zero'], samples_per_word=1)\n",
    "\n",
    "if len(file_paths) > 0:\n",
    "    test_file = file_paths[0]\n",
    "    print(f\"Testing with: {test_file}\")\n",
    "\n",
    "    # Encode\n",
    "    encoded = dac_processor.encode_audio(test_file)\n",
    "\n",
    "    print(\"\\nEncoded Output Shapes:\")\n",
    "    print(f\"  codes: {encoded['codes'].shape}  # [batch, n_codebooks, time]\")\n",
    "    print(f\"  latents: {encoded['latents'].shape}  # [batch, n_codebooks*dim, time]\")\n",
    "    print(f\"  z: {encoded['z'].shape}  # [batch, latent_dim, time]\")\n",
    "    print(f\"  audio_length: {encoded['audio_length']}\")\n",
    "\n",
    "    # Show sample codes\n",
    "    codes = encoded['codes'][0]  # [n_codebooks, time]\n",
    "    print(f\"\\nSample codes from first 5 time steps:\")\n",
    "    print(codes[:, :5].numpy())\n",
    "\n",
    "    # Show code statistics\n",
    "    print(f\"\\nCode Statistics:\")\n",
    "    print(f\"  Min code value: {codes.min().item()}\")\n",
    "    print(f\"  Max code value: {codes.max().item()}\")\n",
    "    print(f\"  Unique codes per codebook:\")\n",
    "    for i in range(codes.shape[0]):\n",
    "        unique = torch.unique(codes[i]).numel()\n",
    "        print(f\"    Codebook {i}: {unique} unique values\")\n",
    "else:\n",
    "    print(\"No audio files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Dataset - 5 Words with 10 Samples Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 words for visualization\n",
    "words = ['zero', 'one', 'two', 'yes', 'no']\n",
    "samples_per_word = 10\n",
    "\n",
    "# Load audio paths\n",
    "file_paths, file_labels = loader.load_word_samples(words, samples_per_word=samples_per_word)\n",
    "\n",
    "print(f\"Total samples: {len(file_paths)}\")\n",
    "print(f\"Label distribution:\")\n",
    "for word in words:\n",
    "    count = file_labels.count(word)\n",
    "    print(f\"  {word}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Codes for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract codes for all samples\n",
    "all_codes = []\n",
    "valid_labels = []\n",
    "\n",
    "for file_path, label in zip(file_paths, file_labels):\n",
    "    try:\n",
    "        encoded = dac_processor.encode_audio(file_path)\n",
    "        codes = encoded['codes'][0]  # [n_codebooks, time]\n",
    "        all_codes.append(codes)\n",
    "        valid_labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully processed {len(all_codes)} samples\")\n",
    "print(f\"Code tensor shape (per sample): {all_codes[0].shape if all_codes else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Token Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create token frequency histograms per word\n",
    "fig, axes = plt.subplots(len(words), model.n_codebooks, figsize=(20, 12))\n",
    "fig.suptitle('Token Frequency Distribution per Word and Codebook', fontsize=16, y=1.00)\n",
    "\n",
    "for word_idx, word in enumerate(words):\n",
    "    # Get codes for this word\n",
    "    word_codes = [all_codes[i] for i, label in enumerate(valid_labels) if label == word]\n",
    "    \n",
    "    if not word_codes:\n",
    "        continue\n",
    "    \n",
    "    # Concatenate across time dimension\n",
    "    word_codes_tensor = torch.cat(word_codes, dim=1)  # [n_codebooks, total_time]\n",
    "    \n",
    "    for codebook_idx in range(model.n_codebooks):\n",
    "        ax = axes[word_idx, codebook_idx]\n",
    "        \n",
    "        # Get codes for this codebook\n",
    "        codes = word_codes_tensor[codebook_idx].numpy()\n",
    "        \n",
    "        # Plot histogram\n",
    "        ax.hist(codes, bins=50, alpha=0.7, edgecolor='black')\n",
    "        \n",
    "        if word_idx == 0:\n",
    "            ax.set_title(f'Codebook {codebook_idx}', fontsize=10)\n",
    "        if codebook_idx == 0:\n",
    "            ax.set_ylabel(word, fontsize=12, rotation=0, ha='right')\n",
    "        \n",
    "        ax.set_xlim(0, model.codebook_size)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dac_token_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: dac_token_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Temporal Token Patterns (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal patterns for a few samples\n",
    "samples_to_show = 3\n",
    "\n",
    "fig, axes = plt.subplots(len(words), samples_to_show, figsize=(15, 12))\n",
    "fig.suptitle('Temporal Token Patterns (9 codebooks over time)', fontsize=16)\n",
    "\n",
    "for word_idx, word in enumerate(words):\n",
    "    word_codes = [all_codes[i] for i, label in enumerate(valid_labels) if label == word]\n",
    "    \n",
    "    for sample_idx in range(min(samples_to_show, len(word_codes))):\n",
    "        ax = axes[word_idx, sample_idx]\n",
    "        \n",
    "        codes = word_codes[sample_idx].numpy()  # [n_codebooks, time]\n",
    "        \n",
    "        # Plot heatmap\n",
    "        im = ax.imshow(codes, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "        \n",
    "        if word_idx == 0:\n",
    "            ax.set_title(f'Sample {sample_idx+1}', fontsize=10)\n",
    "        if sample_idx == 0:\n",
    "            ax.set_ylabel(f'{word}\\nCodebook', fontsize=10)\n",
    "        \n",
    "        ax.set_xlabel('Time Frame')\n",
    "        \n",
    "        # Add colorbar for first plot\n",
    "        if word_idx == 0 and sample_idx == samples_to_show - 1:\n",
    "            plt.colorbar(im, ax=ax, label='Token Index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dac_temporal_patterns.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: dac_temporal_patterns.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Dimensionality Reduction on Flattened Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten codes to create feature vectors\n",
    "# Strategy: Average across time, keep codebook values\n",
    "feature_vectors = []\n",
    "for codes in all_codes:\n",
    "    # codes: [n_codebooks, time]\n",
    "    # Average across time: [n_codebooks]\n",
    "    avg_codes = codes.float().mean(dim=1).numpy()\n",
    "    feature_vectors.append(avg_codes)\n",
    "\n",
    "feature_vectors = np.array(feature_vectors)\n",
    "print(f\"Feature vector shape: {feature_vectors.shape}  # [n_samples, n_codebooks]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(feature_vectors)\n",
    "\n",
    "print(f\"PCA variance explained: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Create color map\n",
    "color_map = {word: px.colors.qualitative.Plotly[i] for i, word in enumerate(words)}\n",
    "\n",
    "# Plotly scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pca_result[mask, 0],\n",
    "        y=pca_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=10, color=color_map[word], opacity=0.7)\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='PCA: DAC Discrete Indices (Time-Averaged)',\n",
    "    xaxis_title='PC 1',\n",
    "    yaxis_title='PC 2',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.write_html('dac_indices_pca.html')\n",
    "fig.show()\n",
    "\n",
    "print(\"Saved: dac_indices_pca.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization\n",
    "perplexity = min(30, len(feature_vectors) - 1)\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
    "tsne_result = tsne.fit_transform(feature_vectors)\n",
    "\n",
    "# Plotly scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=tsne_result[mask, 0],\n",
    "        y=tsne_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=10, color=color_map[word], opacity=0.7)\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='t-SNE: DAC Discrete Indices (Time-Averaged)',\n",
    "    xaxis_title='t-SNE 1',\n",
    "    yaxis_title='t-SNE 2',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.write_html('dac_indices_tsne.html')\n",
    "fig.show()\n",
    "\n",
    "print(\"Saved: dac_indices_tsne.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Max Pooling Strategy (Preserving Prominent Features)\n",
    "\n",
    "**Hypothesis**: Instead of averaging (which destroys temporal information), max pooling captures the most prominent/activated indices across time for each codebook.\n",
    "\n",
    "**Rationale**:\n",
    "- Averaging: `[512, 89, 745] â†’ 448.67` (meaningless average)\n",
    "- Max pooling: `[512, 89, 745] â†’ 745` (captures strongest activation)\n",
    "\n",
    "This might preserve more discriminative information!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract max-pooled feature vectors\n",
    "feature_vectors_max = []\n",
    "for codes in all_codes:\n",
    "    # codes: [n_codebooks, time]\n",
    "    # Max across time: [n_codebooks]\n",
    "    max_codes = codes.float().max(dim=1)[0].numpy()\n",
    "    feature_vectors_max.append(max_codes)\n",
    "\n",
    "feature_vectors_max = np.array(feature_vectors_max)\n",
    "print(f\"Max-pooled feature vector shape: {feature_vectors_max.shape}  # [n_samples, n_codebooks]\")\n",
    "print(f\"\\nComparison (first sample):\")\n",
    "print(f\"  Mean-pooled: {feature_vectors[0][:5]}...\")\n",
    "print(f\"  Max-pooled:  {feature_vectors_max[0][:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization with max pooling\n",
    "pca_max = PCA(n_components=2)\n",
    "pca_result_max = pca_max.fit_transform(feature_vectors_max)\n",
    "\n",
    "print(f\"PCA (Max Pooling) variance explained: {pca_max.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Plotly scatter plot\n",
    "fig_max = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_max.add_trace(go.Scatter(\n",
    "        x=pca_result_max[mask, 0],\n",
    "        y=pca_result_max[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=10, color=color_map[word], opacity=0.7)\n",
    "    ))\n",
    "\n",
    "fig_max.update_layout(\n",
    "    title='PCA: DAC Discrete Indices (Max Pooling)',\n",
    "    xaxis_title='PC 1',\n",
    "    yaxis_title='PC 2',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_max.write_html('dac_indices_pca_maxpool.html')\n",
    "fig_max.show()\n",
    "\n",
    "print(\"Saved: dac_indices_pca_maxpool.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization with max pooling\n",
    "tsne_max = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
    "tsne_result_max = tsne_max.fit_transform(feature_vectors_max)\n",
    "\n",
    "# Plotly scatter plot\n",
    "fig_tsne_max = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_tsne_max.add_trace(go.Scatter(\n",
    "        x=tsne_result_max[mask, 0],\n",
    "        y=tsne_result_max[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=10, color=color_map[word], opacity=0.7)\n",
    "    ))\n",
    "\n",
    "fig_tsne_max.update_layout(\n",
    "    title='t-SNE: DAC Discrete Indices (Max Pooling)',\n",
    "    xaxis_title='t-SNE 1',\n",
    "    yaxis_title='t-SNE 2',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_tsne_max.write_html('dac_indices_tsne_maxpool.html')\n",
    "fig_tsne_max.show()\n",
    "\n",
    "print(\"Saved: dac_indices_tsne_maxpool.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Convert labels to numeric\n",
    "label_to_idx = {word: i for i, word in enumerate(words)}\n",
    "numeric_labels = np.array([label_to_idx[label] for label in valid_labels])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPARISON: MEAN POOLING vs MAX POOLING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Mean pooling metrics\n",
    "sil_mean_pca = silhouette_score(pca_result, numeric_labels)\n",
    "db_mean_pca = davies_bouldin_score(pca_result, numeric_labels)\n",
    "sil_mean_tsne = silhouette_score(tsne_result, numeric_labels)\n",
    "db_mean_tsne = davies_bouldin_score(tsne_result, numeric_labels)\n",
    "\n",
    "print(\"\\n1ï¸âƒ£  MEAN POOLING (Original):\")\n",
    "print(f\"  PCA:   Silhouette = {sil_mean_pca:.4f}  |  Davies-Bouldin = {db_mean_pca:.4f}\")\n",
    "print(f\"  t-SNE: Silhouette = {sil_mean_tsne:.4f}  |  Davies-Bouldin = {db_mean_tsne:.4f}\")\n",
    "\n",
    "# Max pooling metrics\n",
    "sil_max_pca = silhouette_score(pca_result_max, numeric_labels)\n",
    "db_max_pca = davies_bouldin_score(pca_result_max, numeric_labels)\n",
    "sil_max_tsne = silhouette_score(tsne_result_max, numeric_labels)\n",
    "db_max_tsne = davies_bouldin_score(tsne_result_max, numeric_labels)\n",
    "\n",
    "print(\"\\n2ï¸âƒ£  MAX POOLING (New):\")\n",
    "print(f\"  PCA:   Silhouette = {sil_max_pca:.4f}  |  Davies-Bouldin = {db_max_pca:.4f}\")\n",
    "print(f\"  t-SNE: Silhouette = {sil_max_tsne:.4f}  |  Davies-Bouldin = {db_max_tsne:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "print(\"\\nðŸ“Š IMPROVEMENT:\")\n",
    "pca_sil_improvement = sil_max_pca - sil_mean_pca\n",
    "tsne_sil_improvement = sil_max_tsne - sil_mean_tsne\n",
    "pca_db_improvement = db_mean_pca - db_max_pca  # Lower is better, so subtract opposite way\n",
    "tsne_db_improvement = db_mean_tsne - db_max_tsne\n",
    "\n",
    "print(f\"  PCA Silhouette:   {pca_sil_improvement:+.4f} {'âœ… Better' if pca_sil_improvement > 0 else 'âŒ Worse'}\")\n",
    "print(f\"  PCA Davies-Bouldin: {pca_db_improvement:+.4f} {'âœ… Better' if pca_db_improvement > 0 else 'âŒ Worse'}\")\n",
    "print(f\"  t-SNE Silhouette: {tsne_sil_improvement:+.4f} {'âœ… Better' if tsne_sil_improvement > 0 else 'âŒ Worse'}\")\n",
    "print(f\"  t-SNE Davies-Bouldin: {tsne_db_improvement:+.4f} {'âœ… Better' if tsne_db_improvement > 0 else 'âŒ Worse'}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Conclusion:\")\n",
    "if pca_sil_improvement > 0.05 or tsne_sil_improvement > 0.05:\n",
    "    print(\"  Max pooling shows SIGNIFICANT improvement over mean pooling!\")\n",
    "elif pca_sil_improvement > 0.01 or tsne_sil_improvement > 0.01:\n",
    "    print(\"  Max pooling shows marginal improvement over mean pooling.\")\n",
    "else:\n",
    "    print(\"  Max pooling does NOT significantly improve over mean pooling.\")\n",
    "    print(\"  This confirms: temporal information loss is the main issue, not pooling method.\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Max Pooling Results\n",
    "\n",
    "**Key Findings**:\n",
    "- Compared mean pooling vs max pooling for discrete indices\n",
    "- Max pooling captures strongest activations instead of averaging\n",
    "- Check metrics above to see if preserving prominent features helps\n",
    "\n",
    "**Expected**: If max pooling significantly improves clustering, it suggests that peak activations are more discriminative than averages. If not, it confirms that collapsing the temporal dimension (regardless of method) is the fundamental limitation.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook explored DAC's discrete token indices:\n",
    "1. âœ… Loaded and inspected DAC model structure (12 codebooks, 1024 entries each)\n",
    "2. âœ… Extracted codes for multiple audio samples\n",
    "3. âœ… Visualized token frequency distributions per word\n",
    "4. âœ… Created temporal heatmaps showing code patterns over time\n",
    "5. âœ… Applied PCA/t-SNE to time-averaged discrete codes (mean pooling)\n",
    "6. âœ… Compared mean pooling vs max pooling strategies\n",
    "7. âœ… Analyzed clustering metrics to determine if preserving peak activations helps\n",
    "\n",
    "**Key Insight**: Averaging discrete indices (e.g., `[512, 89, 745] â†’ 448.67`) destroys temporal information. Max pooling (`[512, 89, 745] â†’ 745`) preserves the strongest activation but still collapses time. The comparison metrics show whether the pooling method or temporal dimension collapse is the limiting factor.\n",
    "\n",
    "Next: `dac_embeddings_viz.ipynb` will use **continuous codebook embeddings** instead of discrete indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
