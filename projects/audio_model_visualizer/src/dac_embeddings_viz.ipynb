{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Continuous Codebook Embeddings Visualization\n",
    "\n",
    "This notebook extracts and visualizes **continuous codebook embeddings** from DAC.\n",
    "\n",
    "## Approach:\n",
    "- Extract discrete codes (indices) from DAC\n",
    "- Look up continuous embeddings from codebooks\n",
    "- Pool embeddings across time and codebooks\n",
    "- Apply PCA/t-SNE like the main dashboard\n",
    "- Compare clustering quality with Wav2Vec2/Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Import our utilities\n",
    "from dac_utils import DACProcessor, SpeechCommandsLoader, extract_dac_embeddings_batch\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize DAC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dac_processor = DACProcessor(model_type=\"16khz\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test Embedding Extraction on Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a test sample\n",
    "loader = SpeechCommandsLoader()\n",
    "file_paths, labels = loader.load_word_samples(['zero'], samples_per_word=1)\n",
    "\n",
    "if len(file_paths) > 0:\n",
    "    test_file = file_paths[0]\n",
    "    print(f\"Testing with: {test_file}\\n\")\n",
    "    \n",
    "    # Encode to get codes\n",
    "    encoded = dac_processor.encode_audio(test_file)\n",
    "    codes = encoded['codes']  # [1, n_codebooks, time]\n",
    "    \n",
    "    print(f\"Codes shape: {codes.shape}\")\n",
    "    \n",
    "    # Get codebook embeddings\n",
    "    embeddings = dac_processor.get_codebook_embeddings(codes)\n",
    "    print(f\"Codebook embeddings shape: {embeddings.shape}  # [batch, n_codebooks, time, codebook_dim]\")\n",
    "    \n",
    "    # Show embedding statistics\n",
    "    print(f\"\\nEmbedding Statistics:\")\n",
    "    print(f\"  Min: {embeddings.min().item():.4f}\")\n",
    "    print(f\"  Max: {embeddings.max().item():.4f}\")\n",
    "    print(f\"  Mean: {embeddings.mean().item():.4f}\")\n",
    "    print(f\"  Std: {embeddings.std().item():.4f}\")\n",
    "    \n",
    "    # Test pooling\n",
    "    print(f\"\\nPooling Methods:\")\n",
    "    \n",
    "    # Mean pooling across time and codebooks\n",
    "    mean_pooled = embeddings.mean(dim=[1, 2])  # [batch, codebook_dim]\n",
    "    print(f\"  Mean pooled shape: {mean_pooled.shape}\")\n",
    "    # print(f\"  Mean pooled vector: {mean_pooled.squeeze().cpu().numpy()}\")\n",
    "else:\n",
    "    print(\"No audio files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Dataset - 5 Words, 10 Samples Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 words for visualization\n",
    "words = ['zero', 'one', 'two', 'yes', 'no']\n",
    "samples_per_word = 10\n",
    "\n",
    "# Load audio paths\n",
    "file_paths, file_labels = loader.load_word_samples(words, samples_per_word=samples_per_word)\n",
    "\n",
    "print(f\"Total samples: {len(file_paths)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "for word in words:\n",
    "    count = file_labels.count(word)\n",
    "    print(f\"  {word}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Embeddings for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings using mean pooling\n",
    "embeddings, valid_labels = extract_dac_embeddings_batch(\n",
    "    file_paths,\n",
    "    file_labels,\n",
    "    dac_processor,\n",
    "    pooling_method='mean',\n",
    "    use_codebook_embeddings=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: PCA Visualization (2D and 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - 2D\n",
    "pca_2d = PCA(n_components=2, random_state=42)\n",
    "pca_2d_result = pca_2d.fit_transform(embeddings)\n",
    "variance_2d = pca_2d.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"PCA 2D variance explained: {variance_2d:.2%}\")\n",
    "\n",
    "# Create color map\n",
    "color_map = {word: px.colors.qualitative.Plotly[i] for i, word in enumerate(words)}\n",
    "\n",
    "# 2D Plot\n",
    "fig_2d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_2d.add_trace(go.Scatter(\n",
    "        x=pca_2d_result[mask, 0],\n",
    "        y=pca_2d_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=12, color=color_map[word], opacity=0.7, line=dict(width=0.5, color='white'))\n",
    "    ))\n",
    "\n",
    "fig_2d.update_layout(\n",
    "    title=f'PCA 2D: DAC Codebook Embeddings (Variance: {variance_2d:.1%})',\n",
    "    xaxis_title='PC 1',\n",
    "    yaxis_title='PC 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    xaxis=dict(scaleanchor='y', scaleratio=1),  # Equal aspect ratio\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_2d.write_html('dac_embeddings_pca_2d.html')\n",
    "fig_2d.show()\n",
    "\n",
    "print(\"Saved: dac_embeddings_pca_2d.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - 3D\n",
    "pca_3d = PCA(n_components=3, random_state=42)\n",
    "pca_3d_result = pca_3d.fit_transform(embeddings)\n",
    "variance_3d = pca_3d.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"PCA 3D variance explained: {variance_3d:.2%}\")\n",
    "\n",
    "# 3D Plot\n",
    "fig_3d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_3d.add_trace(go.Scatter3d(\n",
    "        x=pca_3d_result[mask, 0],\n",
    "        y=pca_3d_result[mask, 1],\n",
    "        z=pca_3d_result[mask, 2],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=6, color=color_map[word], opacity=0.7, line=dict(width=0))\n",
    "    ))\n",
    "\n",
    "fig_3d.update_layout(\n",
    "    title=f'PCA 3D: DAC Codebook Embeddings (Variance: {variance_3d:.1%})',\n",
    "    scene=dict(\n",
    "        xaxis_title='PC 1',\n",
    "        yaxis_title='PC 2',\n",
    "        zaxis_title='PC 3',\n",
    "        aspectmode='cube',  # Equal aspect ratio\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_3d.write_html('dac_embeddings_pca_3d.html')\n",
    "fig_3d.show()\n",
    "\n",
    "print(\"Saved: dac_embeddings_pca_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: t-SNE Visualization (2D and 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE - 2D\n",
    "perplexity = min(30, len(embeddings) - 1)\n",
    "tsne_2d = TSNE(n_components=2, random_state=42, metric='cosine', perplexity=perplexity)\n",
    "tsne_2d_result = tsne_2d.fit_transform(embeddings)\n",
    "\n",
    "print(f\"t-SNE 2D completed with perplexity={perplexity}\")\n",
    "\n",
    "# 2D Plot\n",
    "fig_tsne_2d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_tsne_2d.add_trace(go.Scatter(\n",
    "        x=tsne_2d_result[mask, 0],\n",
    "        y=tsne_2d_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=12, color=color_map[word], opacity=0.7, line=dict(width=0.5, color='white'))\n",
    "    ))\n",
    "\n",
    "fig_tsne_2d.update_layout(\n",
    "    title=f't-SNE 2D: DAC Codebook Embeddings (Perplexity={perplexity})',\n",
    "    xaxis_title='t-SNE 1',\n",
    "    yaxis_title='t-SNE 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    xaxis=dict(scaleanchor='y', scaleratio=1),  # Equal aspect ratio (critical for t-SNE)\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_tsne_2d.write_html('dac_embeddings_tsne_2d.html')\n",
    "fig_tsne_2d.show()\n",
    "\n",
    "print(\"Saved: dac_embeddings_tsne_2d.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE - 3D\n",
    "tsne_3d = TSNE(n_components=3, random_state=42, metric='cosine', perplexity=perplexity)\n",
    "tsne_3d_result = tsne_3d.fit_transform(embeddings)\n",
    "\n",
    "print(f\"t-SNE 3D completed with perplexity={perplexity}\")\n",
    "\n",
    "# 3D Plot\n",
    "fig_tsne_3d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_tsne_3d.add_trace(go.Scatter3d(\n",
    "        x=tsne_3d_result[mask, 0],\n",
    "        y=tsne_3d_result[mask, 1],\n",
    "        z=tsne_3d_result[mask, 2],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=6, color=color_map[word], opacity=0.7, line=dict(width=0))\n",
    "    ))\n",
    "\n",
    "fig_tsne_3d.update_layout(\n",
    "    title=f't-SNE 3D: DAC Codebook Embeddings (Perplexity={perplexity})',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE 1',\n",
    "        yaxis_title='t-SNE 2',\n",
    "        zaxis_title='t-SNE 3',\n",
    "        aspectmode='cube',  # Equal aspect ratio\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_tsne_3d.write_html('dac_embeddings_tsne_3d.html')\n",
    "fig_tsne_3d.show()\n",
    "\n",
    "print(\"Saved: dac_embeddings_tsne_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Combined Dashboard-Style Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid like the main dashboard\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[\n",
    "        [{'type': 'scatter'}, {'type': 'scatter3d'}],\n",
    "        [{'type': 'scatter'}, {'type': 'scatter3d'}]\n",
    "    ],\n",
    "    subplot_titles=(\n",
    "        f'PCA 2D (Var: {variance_2d:.1%})',\n",
    "        f'PCA 3D (Var: {variance_3d:.1%})',\n",
    "        f't-SNE 2D (Perp: {perplexity})',\n",
    "        f't-SNE 3D (Perp: {perplexity})'\n",
    "    ),\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# PCA 2D (row 1, col 1)\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pca_2d_result[mask, 0],\n",
    "            y=pca_2d_result[mask, 1],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=8, color=color_map[word], opacity=0.7),\n",
    "            showlegend=True,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# PCA 3D (row 1, col 2)\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=pca_3d_result[mask, 0],\n",
    "            y=pca_3d_result[mask, 1],\n",
    "            z=pca_3d_result[mask, 2],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=5, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# t-SNE 2D (row 2, col 1)\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=tsne_2d_result[mask, 0],\n",
    "            y=tsne_2d_result[mask, 1],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=8, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# t-SNE 3D (row 2, col 2)\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=tsne_3d_result[mask, 0],\n",
    "            y=tsne_3d_result[mask, 1],\n",
    "            z=tsne_3d_result[mask, 2],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=5, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text='DAC Codebook Embeddings - Complete Visualization',\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    width=1400,\n",
    "    height=1000,\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Update axes for equal aspect ratio\n",
    "fig.update_xaxes(title_text='PC 1', row=1, col=1, scaleanchor='y', scaleratio=1)\n",
    "fig.update_yaxes(title_text='PC 2', row=1, col=1)\n",
    "fig.update_xaxes(title_text='t-SNE 1', row=2, col=1, scaleanchor='y3', scaleratio=1)\n",
    "fig.update_yaxes(title_text='t-SNE 2', row=2, col=1)\n",
    "\n",
    "# Update 3D scenes\n",
    "fig.update_scenes(aspectmode='cube', row=1, col=2)\n",
    "fig.update_scenes(aspectmode='cube', row=2, col=2)\n",
    "\n",
    "fig.write_html('dac_embeddings_complete.html')\n",
    "fig.show()\n",
    "\n",
    "print(\"Saved: dac_embeddings_complete.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Clustering Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Convert labels to numeric\n",
    "label_to_idx = {word: i for i, word in enumerate(words)}\n",
    "numeric_labels = np.array([label_to_idx[label] for label in valid_labels])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLUSTERING QUALITY METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Original embeddings\n",
    "if len(np.unique(numeric_labels)) > 1 and len(embeddings) > len(np.unique(numeric_labels)):\n",
    "    sil_orig = silhouette_score(embeddings, numeric_labels)\n",
    "    db_orig = davies_bouldin_score(embeddings, numeric_labels)\n",
    "    print(f\"\\nOriginal Embeddings ({embeddings.shape[1]}D):\")\n",
    "    print(f\"  Silhouette Score: {sil_orig:.4f}  (higher is better, range: -1 to 1)\")\n",
    "    print(f\"  Davies-Bouldin Score: {db_orig:.4f}  (lower is better, >0)\")\n",
    "\n",
    "# PCA 2D\n",
    "sil_pca2d = silhouette_score(pca_2d_result, numeric_labels)\n",
    "db_pca2d = davies_bouldin_score(pca_2d_result, numeric_labels)\n",
    "print(f\"\\nPCA 2D:\")\n",
    "print(f\"  Silhouette Score: {sil_pca2d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_pca2d:.4f}\")\n",
    "\n",
    "# PCA 3D\n",
    "sil_pca3d = silhouette_score(pca_3d_result, numeric_labels)\n",
    "db_pca3d = davies_bouldin_score(pca_3d_result, numeric_labels)\n",
    "print(f\"\\nPCA 3D:\")\n",
    "print(f\"  Silhouette Score: {sil_pca3d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_pca3d:.4f}\")\n",
    "\n",
    "# t-SNE 2D\n",
    "sil_tsne2d = silhouette_score(tsne_2d_result, numeric_labels)\n",
    "db_tsne2d = davies_bouldin_score(tsne_2d_result, numeric_labels)\n",
    "print(f\"\\nt-SNE 2D:\")\n",
    "print(f\"  Silhouette Score: {sil_tsne2d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_tsne2d:.4f}\")\n",
    "\n",
    "# t-SNE 3D\n",
    "sil_tsne3d = silhouette_score(tsne_3d_result, numeric_labels)\n",
    "db_tsne3d = davies_bouldin_score(tsne_3d_result, numeric_labels)\n",
    "print(f\"\\nt-SNE 3D:\")\n",
    "print(f\"  Silhouette Score: {sil_tsne3d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_tsne3d:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nNote: Compare these metrics with Wav2Vec2/Whisper from the main dashboard!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated DAC continuous codebook embeddings visualization:\n",
    "\n",
    "1. ✅ Loaded DAC model and extracted discrete codes\n",
    "2. ✅ Converted codes to continuous embeddings using codebook lookup\n",
    "3. ✅ Pooled embeddings across time and codebooks (mean pooling)\n",
    "4. ✅ Applied PCA and t-SNE in 2D and 3D\n",
    "5. ✅ Created interactive Plotly visualizations matching the main dashboard style\n",
    "6. ✅ Computed clustering quality metrics\n",
    "\n",
    "### Key Findings:\n",
    "- DAC embeddings are **8-dimensional** per codebook (9 codebooks total)\n",
    "- Mean pooling across time and codebooks creates compact representations\n",
    "- Clustering quality can be compared with Wav2Vec2/Whisper\n",
    "\n",
    "### Next Steps:\n",
    "- Integrate DAC into the main Flask dashboard\n",
    "- Add DAC as a model option alongside Wav2Vec2 and Whisper\n",
    "- Compare DAC clustering with other models on larger datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
