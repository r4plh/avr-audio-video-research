{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAC Codebook Projections Concatenated (12,288D)\n",
    "\n",
    "This notebook extracts **all 12 codebook projections** and **concatenates** them instead of summing.\n",
    "\n",
    "## Strategy:\n",
    "```\n",
    "Codebook 0: [time, 8] ‚Üí out_proj ‚Üí [time, 1024]\n",
    "Codebook 1: [time, 8] ‚Üí out_proj ‚Üí [time, 1024]\n",
    "...\n",
    "Codebook 11: [time, 8] ‚Üí out_proj ‚Üí [time, 1024]\n",
    "                            ‚Üì\n",
    "              CONCATENATE (not sum!)\n",
    "                            ‚Üì\n",
    "              [time, 12,288]  (12 √ó 1024)\n",
    "                            ‚Üì\n",
    "                   Mean pool time\n",
    "                            ‚Üì\n",
    "                    [12,288D] embedding\n",
    "```\n",
    "\n",
    "**Hypothesis**: This preserves ALL information from each codebook's projection, rather than mixing them via summation. Should give the BEST clustering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our utilities\n",
    "from dac_utils import DACProcessor, SpeechCommandsLoader\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialize DAC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dac_processor = DACProcessor(model_type=\"16khz\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Custom Extraction Function - Concatenate All Codebook Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_codebook_projections_concat(dac_processor, audio_path):\n",
    "    \"\"\"\n",
    "    Extract all 12 codebook projections and concatenate them\n",
    "    \n",
    "    Returns:\n",
    "        12,288D vector (12 codebooks √ó 1024D each, concatenated)\n",
    "    \"\"\"\n",
    "    # Encode audio\n",
    "    encoded = dac_processor.encode_audio(audio_path)\n",
    "    codes = encoded['codes']  # [1, 12, time]\n",
    "    \n",
    "    # Move to device\n",
    "    codes = codes.to(dac_processor.device)\n",
    "    \n",
    "    B, N, T = codes.shape  # batch=1, n_codebooks=12, time\n",
    "    \n",
    "    # Get projected embeddings from each codebook separately\n",
    "    codebook_projections = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Get indices for this codebook\n",
    "        indices = codes[:, i, :]  # [1, time]\n",
    "        \n",
    "        # Get quantizer for this codebook\n",
    "        quantizer = dac_processor.model.quantizer.quantizers[i]\n",
    "        \n",
    "        # Get 8D embeddings from codebook\n",
    "        z_e = quantizer.embed_code(indices)  # [1, time, 8]\n",
    "        z_e = z_e.transpose(1, 2)  # [1, 8, time] - for conv\n",
    "        \n",
    "        # Apply out_proj: 8D ‚Üí 1024D\n",
    "        z_q = quantizer.out_proj(z_e)  # [1, 1024, time]\n",
    "        \n",
    "        # Mean pool across time\n",
    "        z_q_pooled = z_q.mean(dim=2)  # [1, 1024]\n",
    "        \n",
    "        codebook_projections.append(z_q_pooled)\n",
    "    \n",
    "    # Concatenate all 12 projections\n",
    "    concatenated = torch.cat(codebook_projections, dim=1)  # [1, 12288]\n",
    "    \n",
    "    # Convert to numpy\n",
    "    vector = concatenated.squeeze(0).detach().cpu().numpy()  # [12288]\n",
    "    \n",
    "    return vector\n",
    "\n",
    "print(\"Custom extraction function defined!\")\n",
    "print(\"This extracts 12,288D embeddings (12 codebooks √ó 1024D each)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test on Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the extraction\n",
    "loader = SpeechCommandsLoader()\n",
    "file_paths, labels = loader.load_word_samples(['zero'], samples_per_word=1)\n",
    "\n",
    "if len(file_paths) > 0:\n",
    "    test_file = file_paths[0]\n",
    "    print(f\"Testing with: {test_file}\\n\")\n",
    "    \n",
    "    embedding = extract_codebook_projections_concat(dac_processor, test_file)\n",
    "    \n",
    "    print(f\"Embedding shape: {embedding.shape}  # Should be (12288,)\")\n",
    "    print(f\"\\nBreakdown:\")\n",
    "    print(f\"  12 codebooks √ó 1024D per codebook = 12,288D\")\n",
    "    print(f\"\\nFirst 10 values: {embedding[:10]}\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Min: {embedding.min():.4f}\")\n",
    "    print(f\"  Max: {embedding.max():.4f}\")\n",
    "    print(f\"  Mean: {embedding.mean():.4f}\")\n",
    "    print(f\"  Std: {embedding.std():.4f}\")\n",
    "    print(f\"\\n‚úÖ This preserves ALL codebook projections separately!\")\n",
    "else:\n",
    "    print(\"No audio files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Dataset - 5 Words, 10 Samples Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 5 words for visualization\n",
    "words = ['zero', 'one', 'two', 'yes', 'no']\n",
    "samples_per_word = 10\n",
    "\n",
    "# Load audio paths\n",
    "file_paths, file_labels = loader.load_word_samples(words, samples_per_word=samples_per_word)\n",
    "\n",
    "print(f\"Total samples: {len(file_paths)}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "for word in words:\n",
    "    count = file_labels.count(word)\n",
    "    print(f\"  {word}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Concatenated Codebook Projections for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for all samples\n",
    "embeddings_list = []\n",
    "valid_labels = []\n",
    "\n",
    "for file_path, label in tqdm(zip(file_paths, file_labels), total=len(file_paths), desc=\"Extracting concatenated projections\"):\n",
    "    try:\n",
    "        embedding = extract_codebook_projections_concat(dac_processor, file_path)\n",
    "        embeddings_list.append(embedding)\n",
    "        valid_labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "embeddings = np.array(embeddings_list)\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"Final embeddings shape: {embeddings.shape}  # Should be (50, 12288)\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}D\")\n",
    "print(f\"  = 12 codebooks √ó 1024D per codebook\")\n",
    "print(f\"  = CONCATENATED (not summed!)\")\n",
    "print(f\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: PCA Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - 2D\n",
    "pca_2d = PCA(n_components=2, random_state=42)\n",
    "pca_2d_result = pca_2d.fit_transform(embeddings)\n",
    "variance_2d = pca_2d.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"PCA 2D variance explained: {variance_2d:.2%}\")\n",
    "\n",
    "# Create color map\n",
    "color_map = {word: px.colors.qualitative.Plotly[i] for i, word in enumerate(words)}\n",
    "\n",
    "# 2D Plot\n",
    "fig_2d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_2d.add_trace(go.Scatter(\n",
    "        x=pca_2d_result[mask, 0],\n",
    "        y=pca_2d_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=12, color=color_map[word], opacity=0.7, line=dict(width=0.5, color='white'))\n",
    "    ))\n",
    "\n",
    "fig_2d.update_layout(\n",
    "    title=f'PCA 2D: DAC Concatenated Codebook Projections (12,288D) - Variance: {variance_2d:.1%}',\n",
    "    xaxis_title='PC 1',\n",
    "    yaxis_title='PC 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    xaxis=dict(scaleanchor='y', scaleratio=1),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_2d.write_html('dac_codebook_proj_concat_pca_2d.html')\n",
    "fig_2d.show()\n",
    "\n",
    "print(\"Saved: dac_codebook_proj_concat_pca_2d.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA - 3D\n",
    "pca_3d = PCA(n_components=3, random_state=42)\n",
    "pca_3d_result = pca_3d.fit_transform(embeddings)\n",
    "variance_3d = pca_3d.explained_variance_ratio_.sum()\n",
    "\n",
    "print(f\"PCA 3D variance explained: {variance_3d:.2%}\")\n",
    "\n",
    "# 3D Plot\n",
    "fig_3d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_3d.add_trace(go.Scatter3d(\n",
    "        x=pca_3d_result[mask, 0],\n",
    "        y=pca_3d_result[mask, 1],\n",
    "        z=pca_3d_result[mask, 2],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=6, color=color_map[word], opacity=0.7, line=dict(width=0))\n",
    "    ))\n",
    "\n",
    "fig_3d.update_layout(\n",
    "    title=f'PCA 3D: DAC Concatenated Codebook Projections (12,288D) - Variance: {variance_3d:.1%}',\n",
    "    scene=dict(\n",
    "        xaxis_title='PC 1',\n",
    "        yaxis_title='PC 2',\n",
    "        zaxis_title='PC 3',\n",
    "        aspectmode='cube',\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_3d.write_html('dac_codebook_proj_concat_pca_3d.html')\n",
    "fig_3d.show()\n",
    "\n",
    "print(\"Saved: dac_codebook_proj_concat_pca_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: t-SNE Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE - 2D\n",
    "perplexity = min(30, len(embeddings) - 1)\n",
    "tsne_2d = TSNE(n_components=2, random_state=42, metric='cosine', perplexity=perplexity)\n",
    "tsne_2d_result = tsne_2d.fit_transform(embeddings)\n",
    "\n",
    "print(f\"t-SNE 2D completed with perplexity={perplexity}\")\n",
    "\n",
    "# 2D Plot\n",
    "fig_tsne_2d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_tsne_2d.add_trace(go.Scatter(\n",
    "        x=tsne_2d_result[mask, 0],\n",
    "        y=tsne_2d_result[mask, 1],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=12, color=color_map[word], opacity=0.7, line=dict(width=0.5, color='white'))\n",
    "    ))\n",
    "\n",
    "fig_tsne_2d.update_layout(\n",
    "    title=f't-SNE 2D: DAC Concatenated Codebook Projections (12,288D) - Perplexity={perplexity}',\n",
    "    xaxis_title='t-SNE 1',\n",
    "    yaxis_title='t-SNE 2',\n",
    "    width=900,\n",
    "    height=700,\n",
    "    xaxis=dict(scaleanchor='y', scaleratio=1),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_tsne_2d.write_html('dac_codebook_proj_concat_tsne_2d.html')\n",
    "fig_tsne_2d.show()\n",
    "\n",
    "print(\"Saved: dac_codebook_proj_concat_tsne_2d.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE - 3D\n",
    "tsne_3d = TSNE(n_components=3, random_state=42, metric='cosine', perplexity=perplexity)\n",
    "tsne_3d_result = tsne_3d.fit_transform(embeddings)\n",
    "\n",
    "print(f\"t-SNE 3D completed with perplexity={perplexity}\")\n",
    "\n",
    "# 3D Plot\n",
    "fig_tsne_3d = go.Figure()\n",
    "\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig_tsne_3d.add_trace(go.Scatter3d(\n",
    "        x=tsne_3d_result[mask, 0],\n",
    "        y=tsne_3d_result[mask, 1],\n",
    "        z=tsne_3d_result[mask, 2],\n",
    "        mode='markers',\n",
    "        name=word,\n",
    "        marker=dict(size=6, color=color_map[word], opacity=0.7, line=dict(width=0))\n",
    "    ))\n",
    "\n",
    "fig_tsne_3d.update_layout(\n",
    "    title=f't-SNE 3D: DAC Concatenated Codebook Projections (12,288D) - Perplexity={perplexity}',\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE 1',\n",
    "        yaxis_title='t-SNE 2',\n",
    "        zaxis_title='t-SNE 3',\n",
    "        aspectmode='cube',\n",
    "        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "    ),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_tsne_3d.write_html('dac_codebook_proj_concat_tsne_3d.html')\n",
    "fig_tsne_3d.show()\n",
    "\n",
    "print(\"Saved: dac_codebook_proj_concat_tsne_3d.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Combined Dashboard View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[\n",
    "        [{'type': 'scatter'}, {'type': 'scatter3d'}],\n",
    "        [{'type': 'scatter'}, {'type': 'scatter3d'}]\n",
    "    ],\n",
    "    subplot_titles=(\n",
    "        f'PCA 2D (Var: {variance_2d:.1%})',\n",
    "        f'PCA 3D (Var: {variance_3d:.1%})',\n",
    "        f't-SNE 2D (Perp: {perplexity})',\n",
    "        f't-SNE 3D (Perp: {perplexity})'\n",
    "    ),\n",
    "    vertical_spacing=0.12,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# PCA 2D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pca_2d_result[mask, 0],\n",
    "            y=pca_2d_result[mask, 1],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=8, color=color_map[word], opacity=0.7),\n",
    "            showlegend=True,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# PCA 3D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=pca_3d_result[mask, 0],\n",
    "            y=pca_3d_result[mask, 1],\n",
    "            z=pca_3d_result[mask, 2],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=5, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# t-SNE 2D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=tsne_2d_result[mask, 0],\n",
    "            y=tsne_2d_result[mask, 1],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=8, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# t-SNE 3D\n",
    "for word in words:\n",
    "    mask = np.array([label == word for label in valid_labels])\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=tsne_3d_result[mask, 0],\n",
    "            y=tsne_3d_result[mask, 1],\n",
    "            z=tsne_3d_result[mask, 2],\n",
    "            mode='markers',\n",
    "            name=word,\n",
    "            marker=dict(size=5, color=color_map[word], opacity=0.7),\n",
    "            showlegend=False,\n",
    "            legendgroup=word\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='DAC Concatenated Codebook Projections (12,288D) - Complete Visualization',\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    width=1400,\n",
    "    height=1000,\n",
    "    showlegend=True,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='PC 1', row=1, col=1, scaleanchor='y', scaleratio=1)\n",
    "fig.update_yaxes(title_text='PC 2', row=1, col=1)\n",
    "fig.update_xaxes(title_text='t-SNE 1', row=2, col=1, scaleanchor='y3', scaleratio=1)\n",
    "fig.update_yaxes(title_text='t-SNE 2', row=2, col=1)\n",
    "\n",
    "fig.update_scenes(aspectmode='cube', row=1, col=2)\n",
    "fig.update_scenes(aspectmode='cube', row=2, col=2)\n",
    "\n",
    "fig.write_html('dac_codebook_proj_concat_complete.html')\n",
    "fig.show()\n",
    "\n",
    "print(\"Saved: dac_codebook_proj_concat_complete.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Clustering Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numeric\n",
    "label_to_idx = {word: i for i, word in enumerate(words)}\n",
    "numeric_labels = np.array([label_to_idx[label] for label in valid_labels])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLUSTERING QUALITY METRICS - CONCATENATED CODEBOOK PROJECTIONS (12,288D)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Original embeddings\n",
    "if len(np.unique(numeric_labels)) > 1 and len(embeddings) > len(np.unique(numeric_labels)):\n",
    "    sil_orig = silhouette_score(embeddings, numeric_labels)\n",
    "    db_orig = davies_bouldin_score(embeddings, numeric_labels)\n",
    "    print(f\"\\nüöÄ Original Embeddings (12,288D - CONCATENATED PROJECTIONS):\")\n",
    "    print(f\"  Silhouette Score: {sil_orig:.4f}  (higher is better, range: -1 to 1)\")\n",
    "    print(f\"  Davies-Bouldin Score: {db_orig:.4f}  (lower is better, >0)\")\n",
    "\n",
    "# PCA 2D\n",
    "sil_pca2d = silhouette_score(pca_2d_result, numeric_labels)\n",
    "db_pca2d = davies_bouldin_score(pca_2d_result, numeric_labels)\n",
    "print(f\"\\nPCA 2D:\")\n",
    "print(f\"  Silhouette Score: {sil_pca2d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_pca2d:.4f}\")\n",
    "\n",
    "# PCA 3D\n",
    "sil_pca3d = silhouette_score(pca_3d_result, numeric_labels)\n",
    "db_pca3d = davies_bouldin_score(pca_3d_result, numeric_labels)\n",
    "print(f\"\\nPCA 3D:\")\n",
    "print(f\"  Silhouette Score: {sil_pca3d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_pca3d:.4f}\")\n",
    "\n",
    "# t-SNE 2D\n",
    "sil_tsne2d = silhouette_score(tsne_2d_result, numeric_labels)\n",
    "db_tsne2d = davies_bouldin_score(tsne_2d_result, numeric_labels)\n",
    "print(f\"\\nt-SNE 2D:\")\n",
    "print(f\"  Silhouette Score: {sil_tsne2d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_tsne2d:.4f}\")\n",
    "\n",
    "# t-SNE 3D\n",
    "sil_tsne3d = silhouette_score(tsne_3d_result, numeric_labels)\n",
    "db_tsne3d = davies_bouldin_score(tsne_3d_result, numeric_labels)\n",
    "print(f\"\\nt-SNE 3D:\")\n",
    "print(f\"  Silhouette Score: {sil_tsne3d:.4f}\")\n",
    "print(f\"  Davies-Bouldin Score: {db_tsne3d:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nüìä COMPREHENSIVE COMPARISON - ALL DAC APPROACHES:\")\n",
    "print(\"\\n1Ô∏è‚É£  Codebook 8D (averaging across codebooks):\")\n",
    "print(\"    Silhouette: -0.0731  |  Davies-Bouldin: 4.99\")\n",
    "print(\"\\n2Ô∏è‚É£  Codebook 96D (concatenating 12√ó8D):\")\n",
    "print(\"    Silhouette: ~0.1     |  Davies-Bouldin: ~3.5  [Expected]\")\n",
    "print(\"\\n3Ô∏è‚É£  Latent 1024D (summed projections):\")\n",
    "print(\"    Silhouette: -0.0358  |  Davies-Bouldin: 4.06\")\n",
    "print(f\"\\n4Ô∏è‚É£  Codebook Projections 12,288D (concatenated projections) - THIS NOTEBOOK:\")\n",
    "print(f\"    Silhouette: {sil_orig:.4f}  |  Davies-Bouldin: {db_orig:.4f}\")\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   This approach preserves ALL information from each codebook's 1024D projection.\")\n",
    "print(\"   12√ó more dimensions than latent (1024D), 12√ó more than summed approach.\")\n",
    "print(\"   Expected: Should give BEST results if projection diversity matters!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated DAC **concatenated codebook projections (12,288D)**:\n",
    "\n",
    "### **Approach**:\n",
    "- Extract 12 codebook embeddings: Each [time, 8]\n",
    "- Apply each codebook's `out_proj`: 8D ‚Üí 1024D\n",
    "- **Concatenate all 12**: 12 √ó 1024D = 12,288D (instead of summing to 1024D)\n",
    "- Mean pool across time for final embedding\n",
    "\n",
    "### **Hypothesis**:\n",
    "By concatenating instead of summing, we preserve:\n",
    "- ‚úÖ Each codebook's unique projection patterns\n",
    "- ‚úÖ All 12,288 dimensions of information\n",
    "- ‚úÖ No information loss from summation\n",
    "\n",
    "### **Comparison Table**:\n",
    "\n",
    "| Approach | Dimension | Operation | Expected Quality |\n",
    "|----------|-----------|-----------|------------------|\n",
    "| Codebook (avg) | 8D | Average codebooks | ‚ùå Poor |\n",
    "| Codebook (concat) | 96D | Concat 12√ó8D | ‚ö†Ô∏è Medium |\n",
    "| Latent (summed) | 1024D | Sum 12√ó1024D projs | ‚ùå Still poor |\n",
    "| **Projections (concat)** | **12,288D** | **Concat 12√ó1024D projs** | **?** |\n",
    "\n",
    "### **Key Question**:\n",
    "Does preserving each codebook's projection separately (12,288D) improve clustering vs summing them (1024D)?\n",
    "\n",
    "**Check the metrics above to find out!** üî¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
